{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchhd\n",
    "from torchhd.datasets import AirfoilSelfNoise\n",
    "from torchhd import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchmetrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, lr=0.00001) -> None:\n",
    "        super(BaselineModel, self).__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.M = torch.zeros(1, DIMENSIONS)\n",
    "        self.project = embeddings.Projection(num_features, DIMENSIONS)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        sample_hv = self.project(x)\n",
    "        return torchhd.hard_quantize(sample_hv)\n",
    "    \n",
    "    def model_update(self, x, y):\n",
    "        update = self.M + self.lr * (y - (F.linear(x, self.M))) * x\n",
    "        update = update.mean(0)\n",
    "        # print(\"update: \", update)\n",
    "        self.M = update\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.linear(self.encode(x), self.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LevelHVModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_levels=100, lr=0.00001) -> None:\n",
    "        super(LevelHVModel, self).__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.M = torch.zeros(1, DIMENSIONS)\n",
    "        self.project = embeddings.Projection(num_features, DIMENSIONS)\n",
    "        self.num_levels = num_levels\n",
    "        self.embed = embeddings.Level(num_levels, DIMENSIONS, low=-3, high=3)\n",
    "        self.memory = self.embed.weight\n",
    "        \n",
    "    def encode(self, x):\n",
    "        sample_hv = self.project(x)\n",
    "        return torchhd.hard_quantize(sample_hv)\n",
    "    \n",
    "    def model_update(self, x, y):\n",
    "        update = self.M + self.lr * torchhd.bind(x, (self.embed(y)))\n",
    "        update = update.mean(0)\n",
    "        # print(update)\n",
    "        self.M = update\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l = torchhd.bind(self.M, torchhd.inverse(self.encode(x)))\n",
    "        # print(l)\n",
    "        l = torchhd.cleanup(l, self.memory)\n",
    "        # print(l)\n",
    "        i = (self.memory == l).all(dim=1).nonzero().squeeze()\n",
    "        return (((i / self.num_levels) * (self.embed.high - self.embed.low)) + self.embed.low).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = AirfoilSelfNoise('../data', download=True)\n",
    "\n",
    "STD_DEVS = dataset.data.std(0)\n",
    "MEANS = dataset.data.mean(0)\n",
    "TARGET_STD = dataset.targets.std(0)\n",
    "TARGET_MEAN = dataset.targets.mean(0)\n",
    "MINS = dataset.data.min(0).values\n",
    "MAXS = dataset.data.max(0).values\n",
    "TARGET_MINS = dataset.targets.min(0).values\n",
    "TARGET_MAXS = dataset.targets.max(0).values\n",
    "\n",
    "# def transform(x):\n",
    "#     x = x - MINS\n",
    "#     x = x / (MAXS - MINS)\n",
    "#     return x\n",
    "\n",
    "# def target_transform(x):\n",
    "#     x = x - TARGET_MINS\n",
    "#     x = x / (TARGET_MAXS - TARGET_MINS)\n",
    "#     return x\n",
    "\n",
    "def transform(x):\n",
    "    x = x - MEANS\n",
    "    x = x / STD_DEVS\n",
    "    return x\n",
    "\n",
    "\n",
    "def target_transform(x):\n",
    "    x = x - TARGET_MEAN\n",
    "    x = x / TARGET_STD\n",
    "    return x\n",
    "\n",
    "dataset.transform = transform\n",
    "dataset.target_transform = target_transform\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.0000e+02, 0.0000e+00, 3.0480e-01, 7.1300e+01, 2.6634e-03],\n",
       "        [1.0000e+03, 0.0000e+00, 3.0480e-01, 7.1300e+01, 2.6634e-03],\n",
       "        [1.2500e+03, 0.0000e+00, 3.0480e-01, 7.1300e+01, 2.6634e-03],\n",
       "        ...,\n",
       "        [4.0000e+03, 1.5600e+01, 1.0160e-01, 3.9600e+01, 5.2849e-02],\n",
       "        [5.0000e+03, 1.5600e+01, 1.0160e-01, 3.9600e+01, 5.2849e-02],\n",
       "        [6.3000e+03, 1.5600e+01, 1.0160e-01, 3.9600e+01, 5.2849e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.values>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MINS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6220, -0.4701,  0.9841,  1.3125, -0.5425]])\n",
      "tensor([-1.7377])\n"
     ]
    }
   ],
   "source": [
    "item, label = next(iter(train_dataloader))\n",
    "print(item)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BaselineModel(5)\n",
    "model = LevelHVModel(5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: 100%|██████████| 1052/1052 [00:00<00:00, 1698.85it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(1):\n",
    "        for samples, labels in tqdm(train_dataloader, desc=\"Iteration {}\".format(_ + 1)):\n",
    "            samples_hv = model.encode(samples)\n",
    "            model.model_update(samples_hv, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAP([ 0.0006, -0.0004,  0.0007,  ..., -0.0005,  0.0011,  0.0008])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_model = model.M\n",
    "old_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for samples, labels in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "        predictions = model(samples)\n",
    "        predictions = predictions * TARGET_STD + TARGET_MEAN\n",
    "        # print(predictions)\n",
    "        labels = labels * TARGET_STD + TARGET_MEAN\n",
    "        # print(labels)\n",
    "        mse.update(predictions.view(1).cpu(), labels)\n",
    "\n",
    "print(f\"Testing mean squared error of {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: 100%|██████████| 1052/1052 [00:00<00:00, 2040.11it/s]\n",
      "Iteration 2: 100%|██████████| 1052/1052 [00:00<00:00, 2219.40it/s]\n",
      "Iteration 3: 100%|██████████| 1052/1052 [00:00<00:00, 2225.84it/s]\n",
      "Iteration 4: 100%|██████████| 1052/1052 [00:00<00:00, 2286.93it/s]\n",
      "Iteration 5: 100%|██████████| 1052/1052 [00:00<00:00, 2196.82it/s]\n",
      "Iteration 6: 100%|██████████| 1052/1052 [00:00<00:00, 2173.12it/s]\n",
      "Iteration 7: 100%|██████████| 1052/1052 [00:00<00:00, 2280.57it/s]\n",
      "Iteration 8: 100%|██████████| 1052/1052 [00:00<00:00, 2268.37it/s]\n",
      "Iteration 9: 100%|██████████| 1052/1052 [00:00<00:00, 2284.67it/s]\n",
      "Iteration 10: 100%|██████████| 1052/1052 [00:00<00:00, 2226.34it/s]\n",
      "Iteration 11: 100%|██████████| 1052/1052 [00:00<00:00, 2279.76it/s]\n",
      "Iteration 12: 100%|██████████| 1052/1052 [00:00<00:00, 2246.23it/s]\n",
      "Iteration 13: 100%|██████████| 1052/1052 [00:00<00:00, 2275.20it/s]\n",
      "Iteration 14: 100%|██████████| 1052/1052 [00:00<00:00, 2257.18it/s]\n",
      "Iteration 15: 100%|██████████| 1052/1052 [00:00<00:00, 2317.38it/s]\n",
      "Iteration 16: 100%|██████████| 1052/1052 [00:00<00:00, 2223.97it/s]\n",
      "Iteration 17: 100%|██████████| 1052/1052 [00:00<00:00, 2291.06it/s]\n",
      "Iteration 18: 100%|██████████| 1052/1052 [00:00<00:00, 2344.75it/s]\n",
      "Iteration 19: 100%|██████████| 1052/1052 [00:00<00:00, 2274.33it/s]\n",
      "Iteration 20: 100%|██████████| 1052/1052 [00:00<00:00, 2261.61it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(20):\n",
    "        for samples, labels in tqdm(train_dataloader, desc=\"Iteration {}\".format(_ + 1)):\n",
    "            samples_hv = model.encode(samples)\n",
    "            model.model_update(samples_hv, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 451/451 [00:00<00:00, 1635.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean squared error of 9.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "p = []\n",
    "l = []\n",
    "with torch.no_grad():\n",
    "    for samples, labels in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "        predictions = model(samples)\n",
    "        predictions = predictions * TARGET_STD + TARGET_MEAN\n",
    "        labels = labels * TARGET_STD + TARGET_MEAN\n",
    "        mse.update(predictions.view(1).cpu(), labels)\n",
    "        # print(predictions, labels)\n",
    "\n",
    "print(f\"Testing mean squared error of {(mse.compute().item()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAP([-2.0084e-03,  2.4296e-04, -5.9487e-04,  ...,  6.8179e-04,\n",
       "     -2.9832e-04,  3.1204e-05])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-hd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5acc785b295d31f381f77fcf5bd5cbbd84b03074c1dae528b74e6ea3f46fcd6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
